<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Zk Notes RSS Feed]]></title><description><![CDATA[Notes on Crytopgrahy, AI and other stuff]]></description><link>http://ziemann.me</link><generator>GatsbyJS</generator><lastBuildDate>Mon, 05 May 2025 19:22:09 GMT</lastBuildDate><item><title><![CDATA[AI alignment through programmable cryptography]]></title><description><![CDATA[Introduction Recent advances in both programmable cryptography and AI may appear unrelated at first glance, but they have a clear overlap…]]></description><link>http://ziemann.menull</link><guid isPermaLink="false">http://ziemann.menull</guid><pubDate>Mon, 05 May 2025 09:27:45 GMT</pubDate><content:encoded>&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Recent advances in both &lt;a href=&quot;https://0xparc.org/blog/programmable-cryptography-1&quot;&gt;programmable cryptography&lt;/a&gt; and &lt;a href=&quot;https://ourworldindata.org/grapher/test-scores-ai-capabilities-relative-human-performance&quot;&gt;AI&lt;/a&gt; may appear unrelated at first glance, but they have a clear overlap.&lt;/p&gt;
&lt;p&gt;Programmable cryptography offers two key capabilities:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Private computation&lt;/strong&gt;: Allows an external party to execute a computation on your data without learning anything about the data itself.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Verifiable computation&lt;/strong&gt;: Allows one to efficiently check that the party carried out exactly a predefined computation.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;![[Pasted image 20250426111800.png]]
&lt;em&gt;A simplified tree of cryptographic primitives. Source: &lt;a href=&quot;https://0xparc.org/blog/programmable-cryptography-1&quot;&gt;programmable-cryptography&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;AI systems excel at narrowly scoped tasks and are gradually tackling &lt;a href=&quot;https://contextual.ai/blog/plotting-progress-in-ai/&quot;&gt;broader challenges&lt;/a&gt; such as prediction and reasoning. These systems do not follow a single, predetermined algorithm but learn from data, producing behavior that may be far from trivial to interpret. This &lt;em&gt;emergence&lt;/em&gt; of behavior is of increasing interest as AI takes over more and more important tasks, its &lt;a href=&quot;https://www.ibm.com/think/topics/explainable-ai&quot;&gt;explainability&lt;/a&gt; is an active area of research.&lt;/p&gt;
&lt;p&gt;As AI systems advance and surpass humans across an increasing range of tasks, a critical question arises:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;How can we verify that an AI system is behaving as expected?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are two relevant parts to this question:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Understanding how an AI system is behaving in practice&lt;/li&gt;
&lt;li&gt;Properly defining what its expected behavior should be&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In other words, we are looking to see how &lt;em&gt;aligned&lt;/em&gt; the system is (how it should behave) with respect to some objective (its expected behavior).&lt;/p&gt;
&lt;h3&gt;Programmable Cryptography&lt;/h3&gt;
&lt;p&gt;Here, I adopt the definition of the &lt;a href=&quot;https://0xparc.org/blog/programmable-cryptography-1&quot;&gt;article&lt;/a&gt; linked before.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&quot;*We use the term “programmable cryptography” to refer to a second generation of cryptographic primitives that are becoming practical today. The defining feature of these primitives is that they are far more flexible than first-generation cryptography: they allow us to perform general-purpose computation inside or on top of cryptographic protocols.&quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this discussion, our focus is on Succint Non-Interactive ARguments of Knowledge (SNARKs) and their role in &lt;strong&gt;verifying&lt;/strong&gt; the actions of an AI system. Although SNARKs also support privacy (as zkSNARKs), the primary interest regarding AI alignment has to do with its verifiability property. This is because &lt;em&gt;alignment&lt;/em&gt; (something we dicuss later) depends on our ability to confirm that an AI system performed the computation we expected.&lt;/p&gt;
&lt;p&gt;This area of research, widely known as &lt;a href=&quot;https://medium.com/@vid.kersic/demystifying-zkml-0f3dff7194b9&quot;&gt;zkML&lt;/a&gt; is advancing rapidly by merging cryptography and AI.&lt;/p&gt;
&lt;h3&gt;AI Alignment&lt;/h3&gt;
&lt;p&gt;AI alignment is &lt;a href=&quot;https://www.amazon.com/Artificial-Intelligence-A-Modern-Approach/dp/0134610997&quot;&gt;defined&lt;/a&gt; with respect to an &lt;em&gt;objective&lt;/em&gt;. If the AI system advances towards the objective we say that it is &lt;strong&gt;aligned&lt;/strong&gt;, while if it deviates we say it is pursuing unintended objectives.&lt;/p&gt;
&lt;p&gt;The nature of the objective depends on the system. A system such as &lt;a href=&quot;https://deepmind.google/discover/blog/alphazero-shedding-new-light-on-chess-shogi-and-go/&quot;&gt;AlphaZero&lt;/a&gt; simply must win in the game of Go, while others like &lt;a href=&quot;https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/&quot;&gt;AlphaProof&lt;/a&gt; are trained on formal problems and their objective is to correctly derive a proof&lt;/p&gt;
&lt;p&gt;![[Pasted image 20250426105757.png]]
&lt;em&gt;A representation of the training process of AlphaProof: (Source: &lt;a href=&quot;https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/&quot;&gt;blog&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When objectives are well-defined, it is simpler to try to understand when an AI system is not aligned (and notably &lt;a href=&quot;https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf&quot;&gt;Reinforcement Learning (RL)&lt;/a&gt; techniques are well-suited to this kind of problems, because of their verifiability).&lt;/p&gt;
&lt;p&gt;On the other hand, modern large-scale models (such as today&apos;s LLMs) do not have such neatly defined objectives. Their &lt;em&gt;alignment&lt;/em&gt; emerges from the training process, (ie learning to be a helpful assistant), but this doesn&apos;t mean that their behaviour will be predictable for some &lt;a href=&quot;https://www.holisticai.com/red-teaming/chatgpt-4-5-jailbreaking-red-teaming&quot;&gt;out of distribution input&lt;/a&gt;. As AI systems assume roles once performed by humans, the incentive to verify their behavior grows ever stronger.&lt;/p&gt;
&lt;h3&gt;Using SNARKs for alignment verification&lt;/h3&gt;
&lt;p&gt;Recent &lt;a href=&quot;https://arxiv.org/pdf/2402.02675&quot;&gt;research&lt;/a&gt; (and the main catalyst for this post) has been looking for answers on the verifiability of AI systems. Specifically, on how to use SNARKs to verify the behavior of machine learning models, even when those models are closed-source.&lt;/p&gt;
&lt;p&gt;In this paper, the authors propose the use of &lt;em&gt;benchmarks&lt;/em&gt; and &lt;em&gt;proofs of inference&lt;/em&gt; (proving a certain model performed the computation).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&quot;The goal of this work is to remove the need for the public or an end user to trust the model provider. The zkSNARKs enable verification that computational work with a model with weights &lt;span class=&quot;math math-inline&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;H(W)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathnormal&quot; style=&quot;margin-right:0.08125em;&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathnormal&quot; style=&quot;margin-right:0.13889em;&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; occurred, that it produced a given benchmark, and that it was used for a specific inference that is challenged&quot;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Specifically, when a user questions an output, the provider must produce a succinct proof showing that the model with the same weights that generated the published benchmark indeed produced the claimed output for the challenged input.&lt;/p&gt;
&lt;p&gt;To get into more detail, we are given a &lt;em&gt;benchmark&lt;/em&gt; which aggregates &lt;span class=&quot;math math-inline&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;(x, y)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathnormal&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.1667em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathnormal&quot; style=&quot;margin-right:0.03588em;&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; pairs that are being ran on the model (ie proving accuracy for a certain task is &gt;70%) giving us an indication of how the model &quot;behaves&quot; (if we can aggregate information in a certain way, we may indirectly understand how a model behaves in a general sense) though always subject to the dataset used to create the input-output pairs, which is of course a critical aspect.&lt;/p&gt;
&lt;p&gt;![[Screenshot 2025-05-05 at 21.10.46.png]]
*A system diagram of verifiable ML evaluation: (Source: &lt;a href=&quot;https://arxiv.org/pdf/2402.02675&quot;&gt;paper&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;To challenge any response, whoever receives an output &lt;span class=&quot;math math-inline&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;y&apos;&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.9463em;vertical-align:-0.1944em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathnormal&quot; style=&quot;margin-right:0.03588em;&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7519em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; can ask for a &lt;em&gt;proof of inference&lt;/em&gt;, the provider must then create said proof, which must show that the model used weights &lt;span class=&quot;math math-inline&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;W&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.6833em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathnormal&quot; style=&quot;margin-right:0.13889em;&quot;&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; (the same one that produced the benchmark) to produce said output and that it was based on the input &lt;span class=&quot;math math-inline&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x&apos;&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.7519em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathnormal&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7519em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; sent by the user.&lt;/p&gt;
&lt;p&gt;Leveraging ZKPs, we have managed a way to &lt;strong&gt;verify&lt;/strong&gt; that a closed-source AI system being used is the same as a system we know behaves in a certain way!&lt;/p&gt;
&lt;h3&gt;A quick detour: Isaac Asimov&apos;s three laws of robotics&lt;/h3&gt;
&lt;p&gt;A long time ago, in 1942, Isaac Asimov published &quot;Runaround&quot; a short story around the infamous &lt;strong&gt;three laws of robotics&lt;/strong&gt; :&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;A robot may not injure a human being or, through inaction, allow a human being to come to harm.&lt;/li&gt;
&lt;li&gt;A robot must obey orders given it by human beings except where such orders would conflict with the First Law.&lt;/li&gt;
&lt;li&gt;A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;My unfounded belief is that this implied some sort of hardwired constraints in the robot&apos;s programming, but as is well known, AI is mostly based on NNs which resemble something more akin to human cognition than traditional programming&lt;/p&gt;
&lt;p&gt;Were we to deploy robots governed by these laws today, how could we verify that a robot is actually complying with said rules? Though we still don&apos;t have independent intelligent robots running around in our daily lives (but steady &lt;a href=&quot;https://youtu.be/I44_zbEwz_w?si=dSXjHNys9-CBQoAZ&quot;&gt;progress is being done&lt;/a&gt;), thinking about AI alignment is something we must do to ensure that &lt;em&gt;any&lt;/em&gt; artificial intelligence model that is used behaves as we expect it to.&lt;/p&gt;
&lt;h3&gt;Rambling: AI alignment in the age of Robots and AGI&lt;/h3&gt;
&lt;p&gt;As a speculative exercise, imagine combining Asimov’s laws with SNARK-based verification. Theoretically (and in a very broad and ambiguous sense), how could we achieve something like that?&lt;/p&gt;
&lt;p&gt;Well, based on what we discussed, perhaps we could create a dynamic &lt;em&gt;benchmark&lt;/em&gt; managed by society which probes the closed-source systems to indirectly understand what their expected behavior is. These benchmarks must be very elaborate, perhaps aggregating complex test cases into an alignment score (maybe the score could be also automated by an AI system, though we would need that to be compliant as well!)&lt;/p&gt;
&lt;p&gt;Maybe a safer approach would be having open-source models, which can potentially simplify the process of understanding behaviour by using tools in &lt;a href=&quot;https://www.ibm.com/think/topics/explainable-ai&quot;&gt;XAI&lt;/a&gt;. Though that would seem to hinder competition between private companies, &lt;a href=&quot;https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/&quot;&gt;or perhaps not&lt;/a&gt;. I guess we will learn more about it as we see how open and close source models grow in the coming years.&lt;/p&gt;
&lt;p&gt;In an ideal future where proof generation becomes almost instantaneous, every robot action could be accompanied by a ZKP. Verifying each proof would ensure compliance with alignment constraints, reducing the risk of unsafe or unintended behavior. Maybe this process can be the core process that any robot should have, and all security aspects should be linked to it.&lt;/p&gt;
&lt;p&gt;If this actually works somewhat well, issues such as model impersonation or model hacking (which could lead to inappropriate or unsafe behavior), would be hard! Though there is always an attack surface for the core process itself.&lt;/p&gt;
&lt;p&gt;Despite the highly speculative nature (and perhaps complete nonsense) of this last section, it illustrates how verifiable computation will play a pivotal role in the responsible deployment of AI systems in the future.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Trustless Bug Bounties with zkpoex: Proving Exploits without Revealing Them]]></title><description><![CDATA[Special thanks to Abhi, Galexela and Julie for feedback Introduction Smart contract security is crucial for the future of decentralized…]]></description><link>http://ziemann.me/zkpoex/</link><guid isPermaLink="false">http://ziemann.me/zkpoex/</guid><pubDate>Fri, 18 Apr 2025 09:27:45 GMT</pubDate><content:encoded>&lt;p&gt;&lt;em&gt;Special thanks to &lt;a href=&quot;https://x.com/thebookofzk&quot;&gt;Abhi&lt;/a&gt;, &lt;a href=&quot;https://github.com/Alessandro-Cavaliere&quot;&gt;Galexela&lt;/a&gt; and Julie for feedback&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Smart contract security is crucial for the future of decentralized systems. In 2024 alone, over $2 billion was lost to hacks and exploits, highlighting the severe consequences of security vulnerabilities. As the crypto ecosystem grows, the potential impact of these exploits becomes even more significant.&lt;/p&gt;
&lt;p&gt;Hackers hold several advantages in the current landscape. They can silently monitor projects for extended periods, crafting precise exploits while remaining anonymous. Even contracts that have undergone thorough security audits and implemented bug bounty programs remain vulnerable, as attackers are always looking for novel exploit vectors, and auditors (even the best ones) won’t catch everything.&lt;/p&gt;
&lt;p&gt;Bug bounty programs in the crypto ecosystem generally offer rewards to security researchers who find and report vulnerabilities. These frequently involve lengthy verification processes, delayed payments, and sometimes even non-payment. The introduction of third-party escrows attempts to address these issues but only adds another layer of complexity and trust requirements. Furthermore, projects must deal with an influx of false or irrelevant vulnerability reports, making it difficult to identify and address genuine security concerns.&lt;/p&gt;
&lt;h2&gt;Why &lt;em&gt;trustless&lt;/em&gt; vulnerability disclosure matters&lt;/h2&gt;
&lt;p&gt;Revealing detailed exploit information upfront is risky, as &lt;em&gt;whitehats&lt;/em&gt; must coordinate with projects to receive their rewards.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A &lt;em&gt;trustless&lt;/em&gt; solution would level the playing field between attackers and ethical hackers.&lt;/strong&gt; Using zero-knowledge proofs (ZKPs), zkpoex enables &lt;em&gt;trustless&lt;/em&gt; bug bounty submissions by proving an exploit exists without revealing its mechanics.&lt;/p&gt;
&lt;p&gt;This solution elegantly addresses the previous problems. &lt;em&gt;Whitehats&lt;/em&gt; can now submit cryptographic proof of a contract&apos;s vulnerability while keeping exploit details private. Once verified, bounty payments happen automatically. This approach benefits both parties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Whitehats&lt;/em&gt; receive guaranteed, immediate rewards after proof verification.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Teams can fix vulnerabilities discreetly without additional coordination.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Introducing zkpoex: Zero-Knowledge Proof of Exploit&lt;/h2&gt;
&lt;p&gt;zkpoex originally began as a proof-of-concept and won the &lt;a href=&quot;https://risczero.com/blog/zkpoex&quot;&gt;ETHDenver 2023 hackathon&lt;/a&gt;. This project, done by &lt;a href=&quot;https://github.com/zkoranges&quot;&gt;zkoranges&lt;/a&gt; and &lt;a href=&quot;https://github.com/federava&quot;&gt;federava&lt;/a&gt;  though very innovative, was a PoC that was not yet generalizable as a tool to prove arbitrary exploits.&lt;/p&gt;
&lt;p&gt;Together with &lt;a href=&quot;https://github.com/Alessandro-Cavaliere&quot;&gt;galexela&lt;/a&gt; we enhanced this proof of concept into a richer project which can be used by both &lt;em&gt;whitehats&lt;/em&gt; and project owners in order to participate in this protocol.&lt;/p&gt;
&lt;p&gt;At its core, zkpoex allows a &lt;em&gt;whitehat&lt;/em&gt; (the prover) to convincingly demonstrate the exploitability of a smart contract to a project (the verifier) without revealing any specific exploit details. To accomplish this, zkpoex uses ZKPs, cryptographic proofs that verify a statement&apos;s truth without revealing sensitive information. In this context, the proven statement is:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&quot;I know specific calldata that, when executed, violates the contract&apos;s intended security guarantees.&quot;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This proof takes the form of a Zero-Knowledge Succinct Non-Interactive Argument of Knowledge (zkSNARK). The &quot;zk&quot; prefix indicates its zero-knowledge property, which keeps the calldata completely private.&lt;/p&gt;
&lt;p&gt;zkpoex is also researching the notion of encrypting &lt;em&gt;calldata&lt;/em&gt; with a public key within the proof, ensuring that only the affected project&apos;s security team can access the vulnerability details. This feature remains under active research.&lt;/p&gt;
&lt;h2&gt;Key Concepts: How to Prove You&apos;ve Found an Exploit&lt;/h2&gt;
&lt;p&gt;To prove an exploit, projects must first define a set of &lt;strong&gt;conditions&lt;/strong&gt; called the &lt;strong&gt;program specification&lt;/strong&gt;. zkpoex uses this specification to verify whether a &lt;strong&gt;state transition&lt;/strong&gt; invalidates any conditions.&lt;/p&gt;
&lt;p&gt;While creating these conditions requires significant effort, we believe this process leads to safer code. We&apos;re developing tools to streamline this specification process and reduce development time.&lt;/p&gt;
&lt;p&gt;These conditions are straightforward statements that smart contract methods must satisfy, such as &lt;em&gt;&quot;users can&apos;t withdraw more tokens than they deposited&quot;&lt;/em&gt; or &lt;em&gt;&quot;the total token supply must equal the sum of all individual balances.&quot;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When a prover discovers a state transition that breaks a condition, they simulate it and prove the violation. The prover demonstrates a violation exists without revealing the specific exploit.&lt;/p&gt;
&lt;p&gt;Sometimes vulnerabilities stem from incomplete rules rather than broken ones. zkpoex handles this by letting provers suggest additional conditions. A whitehat can effectively say: &lt;em&gt;&quot;If you had included this condition, my transaction would violate it.&quot;&lt;/em&gt; This capability enables the user to improve security, although determining the validity or necessity of these additional conditions is a non-trivial task.&lt;/p&gt;
&lt;p&gt;Some may notice these cases (additional or missing conditions in the specification) challenge the premise of avoiding unfounded claims, since provers can propose arbitrary conditions. This challenge is discussed further in the Challenges and Considerations section.&lt;/p&gt;
&lt;p&gt;In summary, zkpoex addresses two main types of vulnerabilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Exploits&lt;/strong&gt;: Clear violations of existing conditions (program specification).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Missing Conditions&lt;/strong&gt;: Vulnerabilities resulting from incomplete specifications.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;How zkpoex Works: Simulating an Attack in Zero Knowledge&lt;/h2&gt;
&lt;p&gt;Behind the scenes, zkpoex employs both an Ethereum Virtual Machine (EVM) interpreter and a zero-knowledge virtual machine (zkVM) to simulate attacks and generate cryptographic proofs. Currently, zkpoex uses &lt;a href=&quot;https://github.com/rust-ethereum/evm&quot;&gt;Rust EVM&lt;/a&gt; as the interpreter and &lt;a href=&quot;https://dev.risczero.com/api/zkvm/&quot;&gt;RISC Zero’s zkVM&lt;/a&gt;, a general-purpose zkVM based on the RISC-V architecture.&lt;/p&gt;
&lt;p&gt;Here’s a simplified step-by-step overview:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Setup&lt;/strong&gt;: The &lt;em&gt;whitehat&lt;/em&gt; obtains contract bytecode, a valid state, and &lt;em&gt;calldata&lt;/em&gt; that produces an invalid state transition (relative to the program specification).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Simulating the Exploit&lt;/strong&gt;: The zkVM hosts an Ethereum-like environment, executing the exploit transaction exactly as if it should occur &lt;em&gt;onchain&lt;/em&gt;. It checks the resulting state of this simulation against the program specification to detect the exploit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Detecting the Exploit&lt;/strong&gt;: When the simulation is run on the &lt;em&gt;whitehat&apos;s&lt;/em&gt; inputs (the contract bytecode, initial state, and &lt;em&gt;calldata&lt;/em&gt;), a real exploit will result in some condition being violated during the execution. Meanwhile, if no condition is violated, the &lt;em&gt;whitehat’s&lt;/em&gt; finding does not qualify as a real exploit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Proof Generation&lt;/strong&gt;: After execution, zkpoex generates a ZKP stating, &lt;em&gt;&quot;a private exploit exists causing the contract to violate its specification.&quot;&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Proof Submission &amp;#x26; Verification&lt;/strong&gt;: This proof is submitted onchain, verified by a verifier contract. If valid, the contract confirms the vulnerability without ever seeing exploit details.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Automatic Actions&lt;/strong&gt;: Verified proofs immediately trigger automatic bounty payouts and defensive measures like pausing vulnerable contracts.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Encryption for Confidential Submissions&lt;/h3&gt;
&lt;p&gt;For enhanced security, zkpoex can implement encrypted exploit details. &lt;em&gt;Whitehats&lt;/em&gt; encrypt their exploit &lt;em&gt;calldata&lt;/em&gt; using the project&apos;s public key and submit this encrypted data alongside the cryptographic proof. Only the project&apos;s security team can decrypt these details, and only after the bounty payment is complete. While this encryption significantly improves confidentiality, it creates substantial computational overhead in zkVM environments, an issue that remains the focus of ongoing research for more efficient solutions.&lt;/p&gt;
&lt;h2&gt;Challenges and Considerations&lt;/h2&gt;
&lt;p&gt;While &lt;em&gt;trustless&lt;/em&gt; bug bounties are a powerful concept, zkpoex faces several key challenges:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Meaningful Specifications&lt;/strong&gt;: Writing solid program specifications demands deep understanding of smart contract outcomes. Teams must invest significant effort to define these specifications correctly. To reduce this burden, we&apos;re developing libraries and templates for common specifications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance and Scalability&lt;/strong&gt;: Generating ZK proofs is computationally demanding, especially for complex exploits. For this alpha version, we are allowing the use of &lt;a href=&quot;https://risczero.com/bonsai&quot;&gt;Risc0 Bonsai&lt;/a&gt;, although in the future, proving must be done locally to prevent the exploit from leaking. We&apos;re working to optimize performance by exploring the zkVM landscape and any new technologies that may arise.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Security of zkpoex itself&lt;/strong&gt;: Ironically, zkpoex could become a target, bugs in the prover or verifier logic might enable fake proofs of non-existent vulnerabilities. This makes using a highly secure zkVM and proper EVM environment crucial for proof generation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Handling Missing Conditions&lt;/strong&gt;: Handling missing conditions comes with several challenges:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Avoiding unnecessary claims of conditions to projects&lt;/strong&gt;. Although this is largely mitigated today because malicious parties must create a ZKP (which is computationally expensive), we believe that future zkVM efficiency improvements could make this an issue again. For this case, we may require collateral to be locked until the dispute can be settled properly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Effectively enforcing project payouts&lt;/strong&gt;. Since missing conditions were not defined in the program specification, they cannot be easily categorized, making automatic payouts impossible. To address this, ongoing research explores solutions such as implementing a VDF-like system or partially breakable encryption of the encrypted &lt;em&gt;calldata&lt;/em&gt;. These mechanisms could enforce the team to act if the condition reveals an actual exploit, ensuring at least a minimum payout for such cases.&lt;/p&gt;
&lt;p&gt;Determining appropriate payouts remains challenging, however, as assessing the scope of the exploit is difficult. Another possibility includes integrating a dispute resolution system such as &lt;a href=&quot;https://kleros.io/&quot;&gt;Kleros&lt;/a&gt;, which could help categorize vulnerabilities, enabling a fair solution between the prover and the team regarding payout. In the worst case scenario, enforcing a minimum payout for missing conditions could ensure that the prover is never left empty-handed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Current Status and Roadmap&lt;/h2&gt;
&lt;p&gt;zkpoex is under active development, with version 0.1.0 alpha launching soon. Our current focus is on enhancing usability, implementing advanced condition support, and creating libraries to simplify specification development. We&apos;re also working to integrate verifier contracts for a complete testnet demonstration.&lt;/p&gt;
&lt;p&gt;Our vision is bold, we aim to establish zkpoex as the foundation for automated, &lt;em&gt;trustless&lt;/em&gt; bug bounty platforms. By accepting &quot;zk-proof-of-exploit submissions,&quot; projects can attract more researchers through guaranteed payments while handling vulnerabilities discreetly.&lt;/p&gt;
&lt;p&gt;We welcome contributors with expertise in Rust, Ethereum, zero-knowledge cryptography, or security research. The upcoming version 0.1.0 will serve as our initial alpha release, helping us gather valuable community feedback as we refine the framework toward production readiness.&lt;/p&gt;
&lt;h2&gt;Conclusion: Towards Enhanced Security&lt;/h2&gt;
&lt;p&gt;zkpoex is pushing crypto security forward by combining blockchain principles and zero-knowledge cryptography. By allowing ethical hackers to prove vulnerabilities exist without prematurely revealing exploits, zkpoex tackles existing trust issues, improving overall security.&lt;/p&gt;
&lt;p&gt;Wide adoption of zkpoex could substantially reduce crypto exploits while promoting clearer specifications. As projects refine their program specifications, smart contracts become more deterministic and secure, creating a safer ecosystem for all participants.&lt;/p&gt;
&lt;p&gt;Our future vision of zkpoex is analagous to how arbitrage works in finance: if exploits in public smart contracts exist and their specifications are available, it is rational for actors to find said exploits and obtain automatic rewards. This, in turn, allows projects to refine their code by fixing broken conditions or enhancing their program specification. If you can iterate this proccess, eventually you would end up with no &lt;em&gt;bugs&lt;/em&gt;! Of course, practice is never as straight-forward as theory, but this is clearly the end goal.&lt;/p&gt;
&lt;p&gt;In a world that will become increasingly &lt;a href=&quot;https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf&quot;&gt;permeated by AI agents&lt;/a&gt; and where &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S1084804525000396&quot;&gt;research in smart contract vulnerabilities detection is on the rise&lt;/a&gt;, we think leveraging zero-knowledge technology to automate security improvements will be deeply important.&lt;/p&gt;
&lt;p&gt;We invite smart contract developers, ethical hackers, cryptographers, and researchers to explore the &lt;a href=&quot;https://github.com/ziemen4/zkpoex&quot;&gt;zkpoex GitHub repository&lt;/a&gt;, join us on &lt;a href=&quot;https://t.me/+8tMy2kbilaY5MDM0&quot;&gt;Telegram&lt;/a&gt; or &lt;a href=&quot;https://discord.gg/YkyEN2hs&quot;&gt;Discord&lt;/a&gt; and contribute ideas, our mission is to build a safer crypto ecosystem. We are currently seeking grants, if you&apos;re interested in funding this project, please reach out to us.&lt;/p&gt;</content:encoded></item></channel></rss>