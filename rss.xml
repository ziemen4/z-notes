<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Zk Notes RSS Feed]]></title><description><![CDATA[Notes on Crytopgrahy, AI and other stuff]]></description><link>https://ziemann.me</link><generator>GatsbyJS</generator><lastBuildDate>Wed, 28 May 2025 21:54:18 GMT</lastBuildDate><item><title><![CDATA[No title]]></title><description><![CDATA[No drafts!]]></description><link>https://ziemann.menull</link><guid isPermaLink="false">https://ziemann.menull</guid><content:encoded>&lt;p&gt;No drafts!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[AI alignment through programmable cryptography]]></title><description><![CDATA[Special thanks to Julie for feedback Introduction Recently, there have been significant advances both in programmable cryptography and AI…]]></description><link>https://ziemann.me/ai-crypto/</link><guid isPermaLink="false">https://ziemann.me/ai-crypto/</guid><pubDate>Mon, 12 May 2025 09:27:45 GMT</pubDate><content:encoded>&lt;p&gt;&lt;em&gt;Special thanks to Julie for feedback&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Recently, there have been significant advances both in &lt;a href=&quot;https://0xparc.org/blog/programmable-cryptography-1&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;programmable cryptography&lt;/a&gt; and &lt;a href=&quot;https://ourworldindata.org/grapher/test-scores-ai-capabilities-relative-human-performance&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;AI&lt;/a&gt;. These areas may appear unrelated at first glance, but there is a clear overlap between them. In particular, tools in programmable cryptography, which enable privacy and verifiability, will play an important role in how we manage what AI systems do. Two key capabilities that arise in the world of cryptography and can help us achieve that are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Private computation&lt;/strong&gt;: Allows an external party to execute a computation on your data without learning anything about the data itself.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Verifiable computation&lt;/strong&gt;: Enables anyone to verify efficiently that the party executed the predefined computation correctly.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/a3c67eac2f2bcbf6ea89acd4c6dc087b/c27e7/0xPARC-programmable-cryptography-tree.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 56.32911392405063%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAABn0lEQVR42m1S226cMBDl//+lrZrX5rVKW6VKwl7Y3e6NXRNuBhYMBmzPOIORWinNCNnIM2fmHB979qNAa6UyIYtYnCQ5DxlLitL8V+a9hyECYKugUWbh+58+f/l6d/ft/p5aDIBzAcV7MJ1QeqTV2sZgp3EEFMr0BkYDGiydzHiKefdoFcOYlre06YoR/PXm+8OPSxT31qacpzmndki1bloPdrnZPvz8VbUS58lRVvgvfnhljbGnC/v97GflrTa2lgMV0TR0vDRgJtX+HD6+LMqmdZPREr3OYA9oELUjT58Bq8BK2qxVSD+TIgnuLo01johHjEhV1QipNOWur/HTKijqhpKEy4Tc7o/7KKnksDscWcapSyXaThmDDtxqIIyQQ6Nxuz88Pj2zJAVnWHRrV8Fmd77EdbtcB0EYkbQs52LUxNFzE4iz1WQSEvNJBU7AiVutQNHlA1YKnKJJCyXBVUzgsusXq3ValB3YS/S6DAJ+I7OmG2JZfjyfC9HNDv99C/985rUIdn/inJOTpyvbHU5ZWYHT3A5KyL7X5sOH+AbysHZdOlnLwAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;0xPARC-programmable-cryptography-tree.png&quot;
        title=&quot;&quot;
        src=&quot;/static/a3c67eac2f2bcbf6ea89acd4c6dc087b/f058b/0xPARC-programmable-cryptography-tree.png&quot;
        srcset=&quot;/static/a3c67eac2f2bcbf6ea89acd4c6dc087b/c26ae/0xPARC-programmable-cryptography-tree.png 158w,
/static/a3c67eac2f2bcbf6ea89acd4c6dc087b/6bdcf/0xPARC-programmable-cryptography-tree.png 315w,
/static/a3c67eac2f2bcbf6ea89acd4c6dc087b/f058b/0xPARC-programmable-cryptography-tree.png 630w,
/static/a3c67eac2f2bcbf6ea89acd4c6dc087b/40601/0xPARC-programmable-cryptography-tree.png 945w,
/static/a3c67eac2f2bcbf6ea89acd4c6dc087b/78612/0xPARC-programmable-cryptography-tree.png 1260w,
/static/a3c67eac2f2bcbf6ea89acd4c6dc087b/c27e7/0xPARC-programmable-cryptography-tree.png 2144w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;
&lt;em&gt;A simplified tree of cryptographic primitives. Source: &lt;a href=&quot;https://0xparc.org/blog/programmable-cryptography-1&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;programmable-cryptography&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;AI systems excel at narrowly scoped tasks and are gradually tackling &lt;a href=&quot;https://contextual.ai/blog/plotting-progress-in-ai/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;broader challenges&lt;/a&gt; such as prediction and reasoning. These systems do not follow a single, predetermined algorithm, but rather learn from data, producing behaviour that may be far from trivial to interpret. The &lt;em&gt;emergence&lt;/em&gt; of behaviour is of increasing interest as AI takes over more and more important tasks. Its &lt;a href=&quot;https://www.ibm.com/think/topics/explainable-ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;explainability&lt;/a&gt; is an active area of research.&lt;/p&gt;
&lt;p&gt;As AI systems advance and surpass humans across an increasing range of tasks, a critical question arises: &lt;strong&gt;how can we verify that an AI system is behaving as expected?&lt;/strong&gt;
There are two relevant parts to this question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understanding how an AI system is behaving in practice&lt;/li&gt;
&lt;li&gt;Properly defining what its expected behaviour should be&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In other words, we are looking to see how &lt;em&gt;aligned&lt;/em&gt; the system is (how it should behave) with respect to some objective (its expected behaviour).&lt;/p&gt;
&lt;h2&gt;Programmable Cryptography&lt;/h2&gt;
&lt;p&gt;Here, I will be adopting the definition from the previously cited &lt;a href=&quot;https://0xparc.org/blog/programmable-cryptography-1&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;article&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&quot;We use the term “programmable cryptography” to refer to a second generation of cryptographic primitives that are becoming practical today. The defining feature of these primitives is that they are far more flexible than first-generation cryptography: they allow us to perform general-purpose computation inside or on top of cryptographic protocols.&quot; &lt;a href=&quot;https://0xparc.org/blog/programmable-cryptography-1&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Programmable Cryptography&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this discussion, our focus is on Zero-Knowledge Succinct Non-Interactive Arguments of Knowledge (zkSNARKs) and their role in &lt;strong&gt;verifying&lt;/strong&gt; the outputs (or actions) of an AI system. We will focus mainly on the verifiability aspect of SNARKs rather than their privacy properties, though we will see how it is important for certain settings as well.&lt;/p&gt;
&lt;p&gt;In particular, a SNARK is an argument (a type of proof) enabling a prover to provide a guarantee that it performed a particular computation correctly. Broadly speaking, we refer to cryptographic protocols with these guarantees as being part of Verifiable Computing (VC).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&quot;Celebrated theoretical results from the mid-1980s and early 1990s indicated that VC protocols can, at least in principle, accomplish amazing feats. These include enabling a cell phone to monitor the execution of a powerful but untrusted (even malicious) supercomputer, enabling computationally weak peripheral devices (e.g., security card readers) to offload security-critical work to powerful remote servers, or letting a mathematician obtain a high degree of confidence that a theorem is true by looking at only a few symbols of a purported proof.&quot; &lt;em&gt;&lt;a href=&quot;https://people.cs.georgetown.edu/jthaler/ProofsArgsAndZK.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Proofs, Arguments and Zero-Knowledge by Justin Thaler&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This quote should give you some idea of where we are headed here. In fact, there is a powerful system (the AI system) and we want to somehow be able to verify, using much weaker systems, that it is behaving as we expect it to!
Thus, we are interested in something known as &lt;em&gt;AI alignment&lt;/em&gt; (which we will talk about next). This whole area of research, widely known as &lt;a href=&quot;https://opengradient.medium.com/a-gentle-introduction-to-zkml-8049a0e10a04&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;zkML&lt;/a&gt;, is advancing rapidly by merging cryptography and AI.&lt;/p&gt;
&lt;h2&gt;AI Alignment&lt;/h2&gt;
&lt;p&gt;AI alignment is &lt;a href=&quot;https://www.amazon.com/Artificial-Intelligence-A-Modern-Approach/dp/0134610997&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;defined&lt;/a&gt; with respect to an &lt;em&gt;objective&lt;/em&gt;. If the AI system advances towards it, we say that it is &lt;strong&gt;aligned&lt;/strong&gt;, while if it deviates from it we say it is pursuing an unintended objective.
Different AI systems can have different goals. A system such as &lt;a href=&quot;https://deepmind.google/discover/blog/alphazero-shedding-new-light-on-chess-shogi-and-go/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;AlphaZero&lt;/a&gt; must win in the game of Go, while others like &lt;a href=&quot;https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;AlphaProof&lt;/a&gt; are trained on formal problems and their objective is to correctly derive a proof.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/479d0520f3031e8f778409263df36574/78612/AlphaFold-pipeline.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 39.87341772151899%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAAsTAAALEwEAmpwYAAABLUlEQVR42qVQu0oDQRSd/xNsLWysBFsVre1sRBIEUVHxLQgWgokobhUM+GiEoFFTGEwUl93Nzu6dmd07d9Zx8yCl4OHO89zhzDks+wcYUabzsjBDhDG9GgAR4zgmItNn2R9FjDHUx0CFnT1A4YLvV0Ch6QiSaU/suOJN73wVSj5SFkTq7aPTfdByYWHvdX6rUX2O2OxBOL4qprah3sajKt41ME1kZtTMrju2ApOb0PKz4snjyNyVG4D9++2TO7rYnliDpXPBnFq64YjDm+QzwHpLtD0phSSU17VkuSSKZXCj7KXplavvWlOiZAjpuqMKl3h6j7+elVLWktba9745Dwc+AUQUx3YjIIq5r1F3zduhya6GDedJ+VUvW91tsH2UpOgHIefcBm6Plsln/QOJCL7WaqBa9wAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;AlphaFold-pipeline.png&quot;
        title=&quot;&quot;
        src=&quot;/static/479d0520f3031e8f778409263df36574/f058b/AlphaFold-pipeline.png&quot;
        srcset=&quot;/static/479d0520f3031e8f778409263df36574/c26ae/AlphaFold-pipeline.png 158w,
/static/479d0520f3031e8f778409263df36574/6bdcf/AlphaFold-pipeline.png 315w,
/static/479d0520f3031e8f778409263df36574/f058b/AlphaFold-pipeline.png 630w,
/static/479d0520f3031e8f778409263df36574/40601/AlphaFold-pipeline.png 945w,
/static/479d0520f3031e8f778409263df36574/78612/AlphaFold-pipeline.png 1260w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;
&lt;em&gt;A representation of the training process of AlphaProof: (Source: &lt;a href=&quot;https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;blog&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When objectives are well-defined, it is simpler to try to understand when an AI system is not aligned, because it’s easier to verify their behaviour. Notably, these systems typically work in a much more constrained environment and there’s a very clear way to compare their outputs with the expected results.&lt;/p&gt;
&lt;p&gt;On the other hand, modern large-scale models (such as today&apos;s LLMs) do not have such neatly defined objectives. Their &lt;em&gt;alignment&lt;/em&gt; emerges from the training process, (ie learning to be a helpful assistant), but this doesn&apos;t mean that their behaviour will be predictable for some &lt;a href=&quot;https://www.holisticai.com/red-teaming/chatgpt-4-5-jailbreaking-red-teaming&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;out of distribution input&lt;/a&gt;. As AI systems assume roles once performed by humans, the incentive to verify their behaviour grows ever stronger.&lt;/p&gt;
&lt;h2&gt;Using zk-SNARKs for alignment verification&lt;/h2&gt;
&lt;p&gt;Recent &lt;a href=&quot;https://arxiv.org/pdf/2402.02675&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;research&lt;/a&gt; (and the main catalyst for this post) has been looking for answers on the verifiability of AI systems. Specifically, on how to use SNARKs to verify the behaviour of machine learning models, even when those models are closed-source.
In this paper, the authors propose the use of &lt;em&gt;benchmarks&lt;/em&gt; and &lt;em&gt;proofs of inference&lt;/em&gt; (proving a certain model performed the computation).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&quot;The goal of this work is to remove the need for the public or an end user to trust the model provider. The zkSNARKs enable verification that computational work with a model with weights &lt;span class=&quot;math math-inline&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;H(W)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathnormal&quot; style=&quot;margin-right:0.08125em;&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathnormal&quot; style=&quot;margin-right:0.13889em;&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; occurred, that it produced a given benchmark, and that it was used for a specific inference that is challenged&quot; &lt;a href=&quot;https://arxiv.org/pdf/2402.02675&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Verifiable evaluations of machine learning models using zkSNARKs&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Specifically, when a user questions an output, the provider must produce a succinct proof showing that the model with the same weights that generated the published benchmark indeed produced the claimed output for the challenged input.&lt;/p&gt;
&lt;p&gt;To get into more detail, we are given a &lt;em&gt;benchmark&lt;/em&gt; which aggregates &lt;span class=&quot;math math-inline&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;(x, y)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathnormal&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.1667em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathnormal&quot; style=&quot;margin-right:0.03588em;&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; pairs that are being run on the model (ie. proving accuracy for a certain task is &gt;70%) giving us an indication of how the model &quot;behaves&quot;. If we can aggregate information in a certain way, we may indirectly understand how a model will behave in a more general sense. Nevertheless, the result ultimately depends on the dataset used to build the benchmark, making said dataset a &lt;strong&gt;critical&lt;/strong&gt; factor of the process.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/af40c08a25bd66ab7c19a326b9592d7d/c211c/Paper-2402.02675.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 40.50632911392405%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB7klEQVR42jWSy27TQBSG8wLwEmzYsOABkHgLHoANW9ggIWCDxJIHgKoLJNo9KgiK1AVNaNK0kh0ScJPmYmwnvsdxnPiW5GPGCFlHczSe8/3+53dtt9sxc31+D8Zkec5mU7CTz7as+u0mF31B4M/wHR3PsQjDEDlXlvLMhizLqpJ9bZ0VNFWN07aK6QX0tWteP33FyycvUDu/GBg2VxOTZOExslzCKBACWwzDoNVqVfD/laYptbwoudKndAcT1pstB/vvuX3zBndu3eXj1+8oQuDip0Z3Mme/sSJcJBj6gMvLC46Pv9Hv9zFNsxIIgkAAhc1OR6V1LtUCzhpNHj98xLu3B7jBgr5uolszwmVGtN7CriSOYzHTQVGUqpcwTdP+AaV3RVGp1xv0ul3+iJep2EuSJfPAIQxc8UUjpuaEuWcytXSuh8MKImGr1QrbtnFdlyiKqMnNXq8rBkPW6ZrmyQlvnj/j86cvxGnBZa8vbA/xgzn61GEV+0IsZjweVxAZxFbcqQyoAkbiTn6cKdgzm6zIOTo85MH9e+ztfcCL11VY7Y7GLEhojXKKfMVkPKBRP0VRVXzfr0rCkyQRKaclhhWxXC7JBdASVtrNc2HJEqo5U9fDFwluykz8QhllkVKIIB3HqUCLxaJKWK5FUfAXgyZDIxm87iMAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Paper-2402.02675.png&quot;
        title=&quot;&quot;
        src=&quot;/static/af40c08a25bd66ab7c19a326b9592d7d/f058b/Paper-2402.02675.png&quot;
        srcset=&quot;/static/af40c08a25bd66ab7c19a326b9592d7d/c26ae/Paper-2402.02675.png 158w,
/static/af40c08a25bd66ab7c19a326b9592d7d/6bdcf/Paper-2402.02675.png 315w,
/static/af40c08a25bd66ab7c19a326b9592d7d/f058b/Paper-2402.02675.png 630w,
/static/af40c08a25bd66ab7c19a326b9592d7d/40601/Paper-2402.02675.png 945w,
/static/af40c08a25bd66ab7c19a326b9592d7d/78612/Paper-2402.02675.png 1260w,
/static/af40c08a25bd66ab7c19a326b9592d7d/c211c/Paper-2402.02675.png 1502w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;
&lt;em&gt;A system diagram of verifiable ML evaluation: (Source: &lt;a href=&quot;https://arxiv.org/pdf/2402.02675&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;paper&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;To challenge any response, whoever receives an output &lt;span class=&quot;math math-inline&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;y&apos;&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.9463em;vertical-align:-0.1944em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathnormal&quot; style=&quot;margin-right:0.03588em;&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7519em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; can ask for a &lt;em&gt;proof of inference&lt;/em&gt; (a zk-SNARK), the provider must then create said proof, which must show that the model indeed used weights &lt;span class=&quot;math math-inline&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;W&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.6833em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathnormal&quot; style=&quot;margin-right:0.13889em;&quot;&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; (the same ones that produced the benchmark) to produce said output and that it was based on the input &lt;span class=&quot;math math-inline&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x&apos;&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.7519em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathnormal&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7519em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; sent by the user.&lt;/p&gt;
&lt;p&gt;Importantly, the weights &lt;span class=&quot;math math-inline&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;W&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.6833em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathnormal&quot; style=&quot;margin-right:0.13889em;&quot;&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; remain secret. Since the &lt;em&gt;proof&lt;/em&gt; only reveals the &lt;em&gt;hash&lt;/em&gt; of the weights and the weights are a private input (also known as a &lt;em&gt;witness&lt;/em&gt;) then we leverage the powerful Zero-Knowledge (ZK) property to keep them private. In summary, the authors found a way to &lt;strong&gt;verify&lt;/strong&gt; that a closed-source AI system being used by someone &lt;strong&gt;is the same&lt;/strong&gt; system that we know behaves in a certain way for a specific &lt;em&gt;benchmark&lt;/em&gt;!&lt;/p&gt;
&lt;h3&gt;A quick detour: Isaac Asimov&apos;s three laws of robotics&lt;/h3&gt;
&lt;p&gt;In 1942, Isaac Asimov published &quot;Runaround&quot; a short story around the now infamous &lt;strong&gt;three laws of robotics&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;A robot may not injure a human being or, through inaction, allow a human being to come to harm.&lt;/li&gt;
&lt;li&gt;A robot must obey orders given it by human beings except where such orders would conflict with the First Law.&lt;/li&gt;
&lt;li&gt;A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;My unfounded belief is that this implied some sort of hardwired constraints in the robot&apos;s programming, but as is well known by now, AI is actually mostly based on Neural Networks (NN) resembling something more akin to how human brains operate than traditional programming.&lt;/p&gt;
&lt;p&gt;Were we to deploy robots governed by these laws today, how could we verify that any robot is actually complying with said rules? Though we still don&apos;t have independent intelligent robots running around in our daily lives (but steady &lt;a href=&quot;https://youtu.be/I44_zbEwz_w?si=dSXjHNys9-CBQoAZ&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;progress is being made&lt;/a&gt;), thinking about AI alignment is something we must do to ensure that any artificial intelligence model that is used behaves as we expect it to.&lt;/p&gt;
&lt;h3&gt;Rambling: AI alignment in the age of Robots and AGI&lt;/h3&gt;
&lt;p&gt;As a speculative exercise, imagine combining Asimov’s laws with the zkSNARK-based verification scheme we discussed before. Theoretically (and in a very broad and ambiguous sense), how could we achieve something like that?&lt;/p&gt;
&lt;p&gt;Well, based on what we discussed, perhaps we could create a dynamic benchmark managed by society which challenges the closed-source systems in order to indirectly understand what their expected behaviour is. These benchmarks must be very elaborate, perhaps aggregating complex test cases into an alignment score that can imply more general concepts like safety, helpfulness or knowledge. We could even think of a classifier system to do this, though we would need that to be compliant as well!&lt;/p&gt;
&lt;p&gt;Perhaps a safer approach would be having open-source models, which can potentially simplify the process of understanding behaviour by using things like &lt;a href=&quot;https://www.transformer-circuits.pub/2022/mech-interp-essay&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;mechanistic interpretability&lt;/a&gt;. Though mandatory open-source models may seem to hinder competition, we are still early to know &lt;a href=&quot;https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;what the right approach may be&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In an ideal future where proof generation becomes almost instantaneous, every robot action could be accompanied by a SNARK. Verifying each proof would ensure compliance with alignment constraints, reducing the risk of unsafe or unintended behaviour. This verification layer could serve as every robot’s core safeguard, and all security aspects should be designed to protect it.
If this actually works somewhat well, malicious attacks such as model impersonation or model hacking (which could lead to inappropriate or unsafe behaviour) would not be possible, though there is always an attack surface for the core process itself to be hacked.&lt;/p&gt;
&lt;p&gt;Despite the highly speculative nature (and perhaps complete nonsense) of this last section, it illustrates how verifiable computation will play a pivotal role in the responsible deployment of AI systems in the future.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Trustless Bug Bounties with zkpoex: Proving Exploits without Revealing Them]]></title><description><![CDATA[Special thanks to Abhi, Galexela and Julie for feedback Introduction Smart contract security is crucial for the future of decentralized…]]></description><link>https://ziemann.me/zkpoex/</link><guid isPermaLink="false">https://ziemann.me/zkpoex/</guid><pubDate>Fri, 18 Apr 2025 09:27:45 GMT</pubDate><content:encoded>&lt;p&gt;&lt;em&gt;Special thanks to &lt;a href=&quot;https://x.com/thebookofzk&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Abhi&lt;/a&gt;, &lt;a href=&quot;https://github.com/Alessandro-Cavaliere&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Galexela&lt;/a&gt; and Julie for feedback&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Smart contract security is crucial for the future of decentralized systems. In 2024 alone, over $2 billion was lost to hacks and exploits, highlighting the severe consequences of security vulnerabilities. As the crypto ecosystem grows, the potential impact of these exploits becomes even more significant.&lt;/p&gt;
&lt;p&gt;Hackers hold several advantages in the current landscape. They can silently monitor projects for extended periods, crafting precise exploits while remaining anonymous. Even contracts that have undergone thorough security audits and implemented bug bounty programs remain vulnerable, as attackers are always looking for novel exploit vectors, and auditors (even the best ones) won’t catch everything.&lt;/p&gt;
&lt;p&gt;Bug bounty programs in the crypto ecosystem generally offer rewards to security researchers who find and report vulnerabilities. These frequently involve lengthy verification processes, delayed payments, and sometimes even non-payment. The introduction of third-party escrows attempts to address these issues but only adds another layer of complexity and trust requirements. Furthermore, projects must deal with an influx of false or irrelevant vulnerability reports, making it difficult to identify and address genuine security concerns.&lt;/p&gt;
&lt;h2&gt;Why &lt;em&gt;trustless&lt;/em&gt; vulnerability disclosure matters&lt;/h2&gt;
&lt;p&gt;Revealing detailed exploit information upfront is risky, as &lt;em&gt;whitehats&lt;/em&gt; must coordinate with projects to receive their rewards.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A &lt;em&gt;trustless&lt;/em&gt; solution would level the playing field between attackers and ethical hackers.&lt;/strong&gt; Using zero-knowledge proofs (ZKPs), zkpoex enables &lt;em&gt;trustless&lt;/em&gt; bug bounty submissions by proving an exploit exists without revealing its mechanics.&lt;/p&gt;
&lt;p&gt;This solution elegantly addresses the previous problems. &lt;em&gt;Whitehats&lt;/em&gt; can now submit cryptographic proof of a contract&apos;s vulnerability while keeping exploit details private. Once verified, bounty payments happen automatically. This approach benefits both parties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Whitehats&lt;/em&gt; receive guaranteed, immediate rewards after proof verification.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Teams can fix vulnerabilities discreetly without additional coordination.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Introducing zkpoex: Zero-Knowledge Proof of Exploit&lt;/h2&gt;
&lt;p&gt;zkpoex originally began as a proof-of-concept and won the &lt;a href=&quot;https://risczero.com/blog/zkpoex&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;ETHDenver 2023 hackathon&lt;/a&gt;. This project, done by &lt;a href=&quot;https://github.com/zkoranges&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;zkoranges&lt;/a&gt; and &lt;a href=&quot;https://github.com/federava&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;federava&lt;/a&gt;  though very innovative, was a PoC that was not yet generalizable as a tool to prove arbitrary exploits.&lt;/p&gt;
&lt;p&gt;Together with &lt;a href=&quot;https://github.com/Alessandro-Cavaliere&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;galexela&lt;/a&gt; we enhanced this proof of concept into a richer project which can be used by both &lt;em&gt;whitehats&lt;/em&gt; and project owners in order to participate in this protocol.&lt;/p&gt;
&lt;p&gt;At its core, zkpoex allows a &lt;em&gt;whitehat&lt;/em&gt; (the prover) to convincingly demonstrate the exploitability of a smart contract to a project (the verifier) without revealing any specific exploit details. To accomplish this, zkpoex uses ZKPs, cryptographic proofs that verify a statement&apos;s truth without revealing sensitive information. In this context, the proven statement is:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&quot;I know specific calldata that, when executed, violates the contract&apos;s intended security guarantees.&quot;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This proof takes the form of a Zero-Knowledge Succinct Non-Interactive Argument of Knowledge (zkSNARK). The &quot;zk&quot; prefix indicates its zero-knowledge property, which keeps the calldata completely private.&lt;/p&gt;
&lt;p&gt;zkpoex is also researching the notion of encrypting &lt;em&gt;calldata&lt;/em&gt; with a public key within the proof, ensuring that only the affected project&apos;s security team can access the vulnerability details. This feature remains under active research.&lt;/p&gt;
&lt;h2&gt;Key Concepts: How to Prove You&apos;ve Found an Exploit&lt;/h2&gt;
&lt;p&gt;To prove an exploit, projects must first define a set of &lt;strong&gt;conditions&lt;/strong&gt; called the &lt;strong&gt;program specification&lt;/strong&gt;. zkpoex uses this specification to verify whether a &lt;strong&gt;state transition&lt;/strong&gt; invalidates any conditions.&lt;/p&gt;
&lt;p&gt;While creating these conditions requires significant effort, we believe this process leads to safer code. We&apos;re developing tools to streamline this specification process and reduce development time.&lt;/p&gt;
&lt;p&gt;These conditions are straightforward statements that smart contract methods must satisfy, such as &lt;em&gt;&quot;users can&apos;t withdraw more tokens than they deposited&quot;&lt;/em&gt; or &lt;em&gt;&quot;the total token supply must equal the sum of all individual balances.&quot;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When a prover discovers a state transition that breaks a condition, they simulate it and prove the violation. The prover demonstrates a violation exists without revealing the specific exploit.&lt;/p&gt;
&lt;p&gt;Sometimes vulnerabilities stem from incomplete rules rather than broken ones. zkpoex handles this by letting provers suggest additional conditions. A whitehat can effectively say: &lt;em&gt;&quot;If you had included this condition, my transaction would violate it.&quot;&lt;/em&gt; This capability enables the user to improve security, although determining the validity or necessity of these additional conditions is a non-trivial task.&lt;/p&gt;
&lt;p&gt;Some may notice these cases (additional or missing conditions in the specification) challenge the premise of avoiding unfounded claims, since provers can propose arbitrary conditions. This challenge is discussed further in the Challenges and Considerations section.&lt;/p&gt;
&lt;p&gt;In summary, zkpoex addresses two main types of vulnerabilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Exploits&lt;/strong&gt;: Clear violations of existing conditions (program specification).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Missing Conditions&lt;/strong&gt;: Vulnerabilities resulting from incomplete specifications.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;How zkpoex Works: Simulating an Attack in Zero Knowledge&lt;/h2&gt;
&lt;p&gt;Behind the scenes, zkpoex employs both an Ethereum Virtual Machine (EVM) interpreter and a zero-knowledge virtual machine (zkVM) to simulate attacks and generate cryptographic proofs. Currently, zkpoex uses &lt;a href=&quot;https://github.com/rust-ethereum/evm&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Rust EVM&lt;/a&gt; as the interpreter and &lt;a href=&quot;https://dev.risczero.com/api/zkvm/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;RISC Zero’s zkVM&lt;/a&gt;, a general-purpose zkVM based on the RISC-V architecture.&lt;/p&gt;
&lt;p&gt;Here’s a simplified step-by-step overview:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Setup&lt;/strong&gt;: The &lt;em&gt;whitehat&lt;/em&gt; obtains contract bytecode, a valid state, and &lt;em&gt;calldata&lt;/em&gt; that produces an invalid state transition (relative to the program specification).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Simulating the Exploit&lt;/strong&gt;: The zkVM hosts an Ethereum-like environment, executing the exploit transaction exactly as if it should occur &lt;em&gt;onchain&lt;/em&gt;. It checks the resulting state of this simulation against the program specification to detect the exploit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Detecting the Exploit&lt;/strong&gt;: When the simulation is run on the &lt;em&gt;whitehat&apos;s&lt;/em&gt; inputs (the contract bytecode, initial state, and &lt;em&gt;calldata&lt;/em&gt;), a real exploit will result in some condition being violated during the execution. Meanwhile, if no condition is violated, the &lt;em&gt;whitehat’s&lt;/em&gt; finding does not qualify as a real exploit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Proof Generation&lt;/strong&gt;: After execution, zkpoex generates a ZKP stating, &lt;em&gt;&quot;a private exploit exists causing the contract to violate its specification.&quot;&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Proof Submission &amp;#x26; Verification&lt;/strong&gt;: This proof is submitted onchain, verified by a verifier contract. If valid, the contract confirms the vulnerability without ever seeing exploit details.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Automatic Actions&lt;/strong&gt;: Verified proofs immediately trigger automatic bounty payouts and defensive measures like pausing vulnerable contracts.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Encryption for Confidential Submissions&lt;/h3&gt;
&lt;p&gt;For enhanced security, zkpoex can implement encrypted exploit details. &lt;em&gt;Whitehats&lt;/em&gt; encrypt their exploit &lt;em&gt;calldata&lt;/em&gt; using the project&apos;s public key and submit this encrypted data alongside the cryptographic proof. Only the project&apos;s security team can decrypt these details, and only after the bounty payment is complete. While this encryption significantly improves confidentiality, it creates substantial computational overhead in zkVM environments, an issue that remains the focus of ongoing research for more efficient solutions.&lt;/p&gt;
&lt;h2&gt;Challenges and Considerations&lt;/h2&gt;
&lt;p&gt;While &lt;em&gt;trustless&lt;/em&gt; bug bounties are a powerful concept, zkpoex faces several key challenges:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Meaningful Specifications&lt;/strong&gt;: Writing solid program specifications demands deep understanding of smart contract outcomes. Teams must invest significant effort to define these specifications correctly. To reduce this burden, we&apos;re developing libraries and templates for common specifications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance and Scalability&lt;/strong&gt;: Generating ZK proofs is computationally demanding, especially for complex exploits. For this alpha version, we are allowing the use of &lt;a href=&quot;https://risczero.com/bonsai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Risc0 Bonsai&lt;/a&gt;, although in the future, proving must be done locally to prevent the exploit from leaking. We&apos;re working to optimize performance by exploring the zkVM landscape and any new technologies that may arise.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Security of zkpoex itself&lt;/strong&gt;: Ironically, zkpoex could become a target, bugs in the prover or verifier logic might enable fake proofs of non-existent vulnerabilities. This makes using a highly secure zkVM and proper EVM environment crucial for proof generation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Handling Missing Conditions&lt;/strong&gt;: Handling missing conditions comes with several challenges:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Avoiding unnecessary claims of conditions to projects&lt;/strong&gt;. Although this is largely mitigated today because malicious parties must create a ZKP (which is computationally expensive), we believe that future zkVM efficiency improvements could make this an issue again. For this case, we may require collateral to be locked until the dispute can be settled properly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Effectively enforcing project payouts&lt;/strong&gt;. Since missing conditions were not defined in the program specification, they cannot be easily categorized, making automatic payouts impossible. To address this, ongoing research explores solutions such as implementing a VDF-like system or partially breakable encryption of the encrypted &lt;em&gt;calldata&lt;/em&gt;. These mechanisms could enforce the team to act if the condition reveals an actual exploit, ensuring at least a minimum payout for such cases.&lt;/p&gt;
&lt;p&gt;Determining appropriate payouts remains challenging, however, as assessing the scope of the exploit is difficult. Another possibility includes integrating a dispute resolution system such as &lt;a href=&quot;https://kleros.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Kleros&lt;/a&gt;, which could help categorize vulnerabilities, enabling a fair solution between the prover and the team regarding payout. In the worst case scenario, enforcing a minimum payout for missing conditions could ensure that the prover is never left empty-handed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Current Status and Roadmap&lt;/h2&gt;
&lt;p&gt;zkpoex is under active development, with version 0.1.0 alpha launching soon. Our current focus is on enhancing usability, implementing advanced condition support, and creating libraries to simplify specification development. We&apos;re also working to integrate verifier contracts for a complete testnet demonstration.&lt;/p&gt;
&lt;p&gt;Our vision is bold, we aim to establish zkpoex as the foundation for automated, &lt;em&gt;trustless&lt;/em&gt; bug bounty platforms. By accepting &quot;zk-proof-of-exploit submissions,&quot; projects can attract more researchers through guaranteed payments while handling vulnerabilities discreetly.&lt;/p&gt;
&lt;p&gt;We welcome contributors with expertise in Rust, Ethereum, zero-knowledge cryptography, or security research. The upcoming version 0.1.0 will serve as our initial alpha release, helping us gather valuable community feedback as we refine the framework toward production readiness.&lt;/p&gt;
&lt;h2&gt;Conclusion: Towards Enhanced Security&lt;/h2&gt;
&lt;p&gt;zkpoex is pushing crypto security forward by combining blockchain principles and zero-knowledge cryptography. By allowing ethical hackers to prove vulnerabilities exist without prematurely revealing exploits, zkpoex tackles existing trust issues, improving overall security.&lt;/p&gt;
&lt;p&gt;Wide adoption of zkpoex could substantially reduce crypto exploits while promoting clearer specifications. As projects refine their program specifications, smart contracts become more deterministic and secure, creating a safer ecosystem for all participants.&lt;/p&gt;
&lt;p&gt;Our future vision of zkpoex is analagous to how arbitrage works in finance: if exploits in public smart contracts exist and their specifications are available, it is rational for actors to find said exploits and obtain automatic rewards. This, in turn, allows projects to refine their code by fixing broken conditions or enhancing their program specification. If you can iterate this proccess, eventually you would end up with no &lt;em&gt;bugs&lt;/em&gt;! Of course, practice is never as straight-forward as theory, but this is clearly the end goal.&lt;/p&gt;
&lt;p&gt;In a world that will become increasingly &lt;a href=&quot;https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;permeated by AI agents&lt;/a&gt; and where &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S1084804525000396&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;research in smart contract vulnerabilities detection is on the rise&lt;/a&gt;, we think leveraging zero-knowledge technology to automate security improvements will be deeply important.&lt;/p&gt;
&lt;p&gt;We invite smart contract developers, ethical hackers, cryptographers, and researchers to explore the &lt;a href=&quot;https://github.com/ziemen4/zkpoex&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;zkpoex GitHub repository&lt;/a&gt;, join us on &lt;a href=&quot;https://t.me/+8tMy2kbilaY5MDM0&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Telegram&lt;/a&gt; or &lt;a href=&quot;https://discord.gg/YkyEN2hs&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Discord&lt;/a&gt; and contribute ideas, our mission is to build a safer crypto ecosystem. We are currently seeking grants, if you&apos;re interested in funding this project, please reach out to us.&lt;/p&gt;</content:encoded></item></channel></rss>